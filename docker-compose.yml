services:
  # --- The Waiter (API) ---
  api:
    build: .
    container_name: review_classifier_api
    # Command to run the API server
    command: uvicorn api:app --host 0.0.0.0 --port 8001
    ports:
      - "8001:8001"
    volumes:
      # The "Safe" for data persistence (Named Volume)
      - app_data:/app
    environment:
      # The "Tunnel" to your local Ollama
      - OLLAMA_HOST=http://host.docker.internal:11434
    extra_hosts:
      # The definition of the host gateway
      - "host.docker.internal:host-gateway"
    restart: always

  # --- The Cook (Worker) ---
  worker:
    build: .
    container_name: review_classifier_worker
    # Command to run the background worker
    command: python worker.py
    volumes:
      # Uses the SAME "Safe" as the API
      - app_data:/app
    environment:
      # Worker also needs the tunnel to Ollama
      - OLLAMA_HOST=http://host.docker.internal:11434
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - api
    restart: always

# Define the "Safe" (Named Volume)
volumes:
  app_data:
